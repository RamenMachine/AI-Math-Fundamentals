# HW1 - Gradient Descent Analysis

## Overview
Implementation of 1D and 2D gradient descent algorithms with convergence analysis and learning rate experiments.

## Files
- `HW1.py` - Main gradient descent implementation (Problems 9 & 10)
- `pweek1.py` - Python fundamentals: Sigmoid, averaging, and basic gradient descent functions

## Key Concepts
- Gradient descent optimization
- Learning rate effects on convergence
- 1D vs 2D optimization comparison
- Mathematical analysis of parabolic functions

## Usage
```bash
python HW1.py
```

Output includes step-by-step calculations, convergence analysis, and comparison of different parameters.